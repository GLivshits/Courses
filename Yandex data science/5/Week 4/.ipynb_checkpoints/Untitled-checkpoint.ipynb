{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('coursera_sessions_train.txt', 'r')\n",
    "data = []\n",
    "\n",
    "for item in file.readlines():\n",
    "    \n",
    "    data.append(item)\n",
    "\n",
    "to_pop = []\n",
    "\n",
    "for idx, item in enumerate(data):\n",
    "    \n",
    "    a = item.split(';')\n",
    "    \n",
    "    if a[1] == '\\n':\n",
    "        \n",
    "        to_pop.append(item)\n",
    "        \n",
    "# data1 = np.copy(data)        \n",
    "        \n",
    "# for obj in to_pop:\n",
    "    \n",
    "#     data.remove(obj)\n",
    "    \n",
    "for i in range(len(data)):\n",
    "    \n",
    "    data[i] = data[i].replace('\\n', '')\n",
    "    \n",
    "checked = []\n",
    "bought = []\n",
    "\n",
    "for item in data:\n",
    "    \n",
    "    checked.append(item.split(';')[0])\n",
    "    \n",
    "    if item.split(';')[1] != '':\n",
    "    \n",
    "        bought.append(item.split(';')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids_checked = []\n",
    "\n",
    "for item in checked:\n",
    "    \n",
    "    for k in item.split(','):\n",
    "        \n",
    "        all_ids_checked.append(int(k))\n",
    "        \n",
    "all_ids_checked = np.array(all_ids_checked)\n",
    "checked_ids, checked_ids_freq = np.unique(all_ids_checked, return_counts = True)\n",
    "\n",
    "idx_checked = checked_ids_freq.argsort()[::-1]\n",
    "\n",
    "checked_ids = checked_ids[idx_checked]\n",
    "checked_ids_freq = checked_ids_freq[idx_checked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids_bought = []\n",
    "\n",
    "for item in bought:\n",
    "    \n",
    "    for k in item.split(','):\n",
    "        \n",
    "        all_ids_bought.append(int(k))\n",
    "        \n",
    "all_ids_bought = np.array(all_ids_bought)\n",
    "\n",
    "bought_ids, bought_ids_freq = np.unique(all_ids_bought, return_counts = True)\n",
    "\n",
    "idx_bought = bought_ids_freq.argsort()[::-1]\n",
    "\n",
    "bought_ids = bought_ids[idx_bought]\n",
    "bought_ids_freq = bought_ids_freq[idx_bought]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_rec_metrics(session, reccomendations, k):\n",
    "    \n",
    "    purchase = 0\n",
    "    \n",
    "    for ind in reccomendations:\n",
    "        \n",
    "        if ind in session:\n",
    "            \n",
    "            purchase += 1 \n",
    "            \n",
    "    precision = purchase / k\n",
    "    recall = purchase / len(session)\n",
    "    return(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77064"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(checked_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_at_1_tr_l, rec_at_1_tr_l = [], []\n",
    "prec_at_5_tr_l, rec_at_5_tr_l = [], []\n",
    "\n",
    "k1, k5 = 1, 5\n",
    "\n",
    "for i, sess_p in enumerate(data):\n",
    "    # skip sessions without purchases\n",
    "    if sess_p == []: continue\n",
    "    \n",
    "    # looks ids\n",
    "    sess_l = sess_train_l[i]\n",
    "\n",
    "    # sorted looks ids indices in sess_train_l_cnt array\n",
    "    # sort in accordance with looks counts\n",
    "    l_ind_sess = []\n",
    "    for j in range(len(sess_l)):\n",
    "        l_ind_sess.append(np.where(sess_train_l_cnt[:,0] == sess_l[j])[0][0])\n",
    "    l_ind_sess_sorted = np.unique(l_ind_sess)\n",
    "    \n",
    "    # k1 recommendations\n",
    "    num_of_recs_k1 = min(k1, len(sess_l))\n",
    "    if num_of_recs_k1 == 0: continue\n",
    "    recs_k1 = sess_train_l_cnt[l_ind_sess_sorted[:num_of_recs_k1],0]\n",
    "    \n",
    "    # k1 metrics\n",
    "    prec_1, rec_1 = prec_rec_metrics(sess_p, recs_k1, k1)\n",
    "    prec_at_1_tr_l.append(prec_1)\n",
    "    rec_at_1_tr_l.append(rec_1)\n",
    "    \n",
    "    # k5 recommendations\n",
    "    num_of_recs_k5 = min(k5, len(sess_l))\n",
    "    if num_of_recs_k5 == 0: continue\n",
    "    recs_k5 = sess_train_l_cnt[l_ind_sess_sorted[:num_of_recs_k5],0]\n",
    "    \n",
    "    # k5 metrics\n",
    "    prec_5, rec_5 = prec_rec_metrics(sess_p, recs_k5, k5)\n",
    "    prec_at_5_tr_l.append(prec_5)\n",
    "    rec_at_5_tr_l.append(rec_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
